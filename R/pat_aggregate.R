#' @keywords pa_timeseries
#' @export
#' @importFrom rlang .data
#' @importFrom stats aggregate median na.omit quantile sd t.test time
#'
#' @title Aggregation statistics for PrupleAir time series
#' 
#' @param pat PurpleAir Timeseries "pat" object
#' @param period The time period to average to. Can be "sec", "min", "hour", 
#' "day", "DSTday", "week", "month", "quarter" or "year". A number can also
#'  precede these options followed by a space (i.e. "2 day" or "37 min").
#' 
#' @description Calculates statistics associated with the aggregation of raw 
#' Purple Air Timeseries data onto a regular time axis.
#' 
#' Temporal aggregation involves creating time period bins defined by
#' \code{period} and then calculating the statistics associated with the raw
#' data measurements that fall within each bin. The result is a dataframe with
#' a regular time axis and multiple columns of output for every column of
#' input.
#' 
#' Each of the \emph{pat} object data columns will result in the following
#' basic statistics:
#' 
#' \enumerate{
#' \item{\code{mean}}
#' \item{\code{median}}
#' \item{\code{sd}}
#' \item{\code{min}}
#' \item{\code{max}}
#' \item{\code{count}}
#' }
#' 
#' For the paired \code{pm25_A} and \code{pm25_B} data columns, the following 
#' additional statistics are generated by applying a two-sample t-test to the 
#' A and B channel data in each bin:
#' 
#' \enumerate{
#' \item{\code{pm25_t} -- t-test statistic}
#' \item{\code{pm25_p} -- p-value}
#' \item{\code{pm25_df} -- degrees of freedom}
#' }
#' 
#' These statistics are used to assign aggregate (hourly) values, (\emph{e.g.}
#' \code{temperature_mean}). They can also be used to invalidate some aggregate 
#' values based on \code{sd}, \code{count} or \code{pm25_t}.
#' 
#' @return Returns a dataframe with aggregation statistics.
#' 
#' @examples
#' \dontrun{
#' df <- pat_aggregate(pat, "1 hour")
#' }

pat_aggregate <- function(
  pat, 
  period = "1 hour"
) {
  
  # ===== DEBUGGING ============================================================
  
  if ( FALSE ) {
    
    pat <- 
      example_pat_failure_B %>%
      pat_filterDate(20190611,20190611)
    
    period <- "1 hour"
    stat <- "tstats"
    parameters <- c("pm25_A", "pm25_B", "humidity", "temperature")
    
  }
  
  # ----- Validate parameters --------------------------------------------------
  
  tolower(period) -> period

  if ( !pat_isPat(pat) )
    stop("Required parameter 'pat' is not a valid 'pa_timeseries' object.")
  
  if ( pat_isEmpty(pat) )
    stop("Required parameter 'pat' has no data.") 
  
  # ----- Convert period to seconds --------------------------------------------
  
  periodParts <- strsplit(period, " ", fixed = TRUE)[[1]]
  
  if ( length(periodParts) == 1 ) {
    periodCount <- 1
    units <- periodParts[1]
  } else {
    periodCount <- as.numeric(periodParts[1])
    units <- periodParts[2]
  }

  if ( units == "sec"     ) unitSecs <- 1
  if ( units == "min"     ) unitSecs <- 60
  if ( units == "hour"    ) unitSecs <- 3600
  if ( units == "day"     ) unitSecs <- 3600 * 24
  if ( units == "week"    ) unitSecs <- 3600 * 24 * 7
  if ( units == "month"   ) unitSecs <- 3600 * 24 * 31
  if ( units == "quarter" ) unitSecs <- 3600 * 24 * 31 * 3
  if ( units == "year"    ) unitSecs <- 3600 * 8784 
  
  periodSeconds <- periodCount * unitSecs 
  
  # ---- Calculate aggregation statistics --------------------------------------
  
  parameters <- c("pm25_A", "pm25_B", "humidity", "temperature")
    
  # Apply .pat_agg separately for each type of statistic
  aggregationStats <- 
    plyr::join_all(
      list(
        .pat_agg(pat, "tstats", periodSeconds, parameters),
        .pat_agg(pat, "mean", periodSeconds, parameters),
        .pat_agg(pat, "median", periodSeconds, parameters),
        .pat_agg(pat, "sd", periodSeconds, parameters), 
        .pat_agg(pat, "min", periodSeconds, parameters), 
        .pat_agg(pat, "max", periodSeconds, parameters),
        .pat_agg(pat, "count", periodSeconds, parameters)
      ),
      by = "datetime"
    ) %>%
    # Deal with periods that had no data where mean,min,max generated NaN or Inf
    dplyr::mutate_all( function(x) replace(x, which(is.nan(x)), NA) ) %>%
    dplyr::mutate_all( function(x) replace(x, which(is.infinite(x)), NA) )

  
  # Re-arrange order of columns to group by input column
  aggregationStats <-
    aggregationStats[,
              c(
                "datetime", 
                names(aggregationStats)[c(
                  grep("pm25_", names(aggregationStats)), 
                  grep("humid", names(aggregationStats)), 
                  grep("temp", names(aggregationStats))
                )]
              )]
  
  
  # ----- Return ---------------------------------------------------------------
  
  return(aggregationStats)
  
}

# ===== INTERNAL FUNCTION ======================================================

.pat_agg <- function(pat, stat, periodSeconds, parameters) {
  
  options(warn = -1) # Ignore all warnings
  
  if ( stat == "mean"       ) func <- function(x) mean(x, na.rm = TRUE)
  if ( stat == "median"     ) func <- function(x) median(x, na.rm = TRUE) 
  if ( stat == "count"      ) func <- function(x) length(na.omit(x))
  if ( stat == "sd"         ) func <- function(x) sd(x, na.rm = TRUE)
  if ( stat == "sum"        ) func <- function(x) sum(na.omit(x))
  if ( stat == "max"        ) func <- function(x) max(na.omit(x))
  if ( stat == "min"        ) func <- function(x) min(na.omit(x))
  if ( stat == "tstats"     ) func <- function(x) x 
  
  # ----- Handle single-input statistics ---------------------------------------
  
  if ( stat != "tstats" ) {

    # Data only input dataframe    
    data <- 
      pat$data %>%  
      dplyr::select(parameters)
    
    datetime <- pat$data$datetime
    
    # Create a 'zoo' object so that we can use zoo::aggregate()
    zz <- 
      zoo::zoo(
        data, 
        structure(
          datetime, 
          class = c("POSIXt", "POSIXct")
        )
      )
    
    tbl <- 
      # Aggregate data by bin and calculate a single-value statistic for the
      # measurements within each bin. With an initial object of type "zoo",
      # the function here is actually zoo::aggregate.zoo() which isn't exported
      # so we can't call it explicitly and have to rely on "dispatching".
      aggregate(
        zz, 
        by = time(zz) - as.numeric(time(zz)) %% periodSeconds, 
        FUN = func, 
        simplify = TRUE
      ) %>%
      # Use "datetime" as the zoo index
      zoo::fortify.zoo(
        names = c(Index = "datetime")
      ) %>% 
      # Rename columns as parameter_stat
      dplyr::rename_at(
        dplyr::vars(2:(ncol(data) + 1)),
        .funs = function(x) paste0(x, "_", stat) # functionally name
      ) %>% 
      dplyr::as_tibble()
    
    return(tbl)
    
  }
  
  # ----- Handle tstats --------------------------------------------------------
  
  if ( stat == "tstats" ) {
    
    # Create an aggregated time axis first
    
    # NOTE:  Use zoo style aggregation to guarantee we get the same datetime axis.
    # NOTE:  If datetime differs by any time at all, plyr::join_all() will fail
    # NOTE:  to properly join dataframes.
    # NOTE:  This time axis is also important for calculating binIndex as we
    # NOTE:  want to calculate binIndex relative the the aggregation unit
    # NOTE:  boundaries.
    
    tt <- as.numeric(pat$data$datetime)
    x <- zoo::zoo(tt, structure(tt, class = c("POSIXt", "POSIXct")))
    dummy <- aggregate(x, time(x) - as.numeric(time(x)) %% periodSeconds, mean)
    aggregatedTimeAxis <- time(dummy)

    # TODO:  We can't do the same zoo::aggregate magic with tstats.
    # TODO:  The documentation clearly states that FUN:
    # TODO:
    # TODO:    "Always needs to return a result of fixed length (typically scalar)."
    # TODO:
    # TODO:  So we roll our own dplyr based aggregation
    
    data <-
      pat$data %>%
      dplyr::select("datetime", "pm25_A", "pm25_B")
    
    # Create a binIndex column
    firstTime <- aggregatedTimeAxis[1]
    elapsedSeconds <- as.numeric(difftime(data$datetime, firstTime, units = "secs"))
    data$binIndex <- floor(elapsedSeconds / periodSeconds) + 1
    
    dataList <- 
      data %>%
      dplyr::group_split(.data$binIndex)
    
    # NOTE:  T-tests should only be used when n < 30. Any larger, the 
    # NOTE:  distribution approches normal -> should use Z test when n > 30.
    # NOTE:  n > 30 ~ period = 30 min 
    
    t_score <-  p_value <- df_value <-  list()
    
    for ( i in seq_along(dataList) ) { 
      
      result <- 
        try({
          htest <- 
            t.test(
              dataList[[i]]$pm25_A, 
              dataList[[i]]$pm25_B, 
              paired = FALSE
            )}, 
          silent = TRUE
        )
      
      if ( "try-error" %in% class(result) ) {
        
        t_score[[i]] <- NA
        p_value[[i]] <- NA 
        df_value[[i]] <- NA
        
      } else {
        
        t_score[[i]] <- as.numeric(htest$statistic)
        p_value[[i]] <- as.numeric(htest$p.value)
        df_value[[i]] <- as.numeric(htest$parameter)
        
      }
      
    }
    
    tbl <- 
      dplyr::tibble(
        datetime = aggregatedTimeAxis, 
        pm25_t = unlist(t_score), 
        pm25_p = unlist(p_value),
        pm25_df = unlist(df_value)
      )
    
    # TODO: Z - Test
    
    options(warn=0)
    
    return(tbl)
    
  }
  
}


