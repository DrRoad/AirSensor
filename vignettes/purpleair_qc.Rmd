---
title: "Purple Air Quality Control"
author: "Mazama Science"
date: "2019-06-18"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Purple Air Qualitiy Control}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(fig.width=7, fig.height=5)
library(AirSensor)
```

This vignette decribes Quality Control (QC) functions and best practices for
working with Purple Air Sensor internals.

## Raw "Engineering" Data

The **AirSensor** package *pat* data model and associated functions make it easy
to work with raw Purple Air data. Each *pat* object provides unmodified data
obtained from the *ThingSpeak* database. (ThingSpeak is the Internt of Things 
data provider that Purple Air has partnered with to handle access to archival
data.)

See the pat_introduction vignette for details.

### Good Data

Lets begin by looking at one week's worth of trouble free sensor data:

```{r example_pat_basic}
pat <- example_pat %>% pat_filterDate(20180701, 20180708)
# use sampleSize = NULL to force display of every data point
pat_multiplot(pat, sampleSize = NULL)
```

In this case, no obvious errors are seen in the data.

### Bad Humitidy Values, Noisy Channel A

Occasionally one sees aphysical relative humidity values > 100. The example
below also shows one of the particle detectors generating noisy data.

```{r example_pat_failure_basic}
pat <- example_pat_failure
# use sampleSize = NULL to force display of every data point
pat_multiplot(pat, sampleSize = NULL)
```

### Out-of-spec PM2.5 Values

One of the PM2.5 channels can also report completely bogus data:

```{r example_pat_failure_B_basic}
pat <- example_pat_failure_B
# use sampleSize = NULL to force display of every data point
pat_multiplot(pat, sampleSize = NULL)
```

## Raw Data QC

The examples above demonstrate just two of many possible failure modes but they 
provide data we can use to devel basic QC algorithms that identify the most 
egregiously misbehaving dat without throwing away potentially interesting 
outliers.

The least controversial QC is the removal of values that are out-of-spec for
the sensor. Purple Air provides 
[PA-II sensor specs](https://www2.purpleair.com/products/purpleair-pa-ii)
which define the valid measurement range for each variable:

```
  0 <   humidity  < 100
-40 < temperature < 185
  0 <     pm25    < 1000
```

The `pat_qc()` function applies these thresholds and returns a *pat* object
where out-of-spec values have been replaced by `NA`. See how the out-of-spec
humidity values get replaced in `example_pat_failure`:

```{r example_pat_failure_qc1}
pat <-
  example_pat_failure %>%
  pat_qc()
pat_multiplot(pat, sampleSize = NULL)
```

The case of `example_pat_failure_B` is also improved by removing out-of-spec
values but some questionable data still exist in channel A:

```{r example_pat_failure_B_qc1}
pat <-
  example_pat_failure_B %>%
  pat_qc()
pat_multiplot(pat, sampleSize = NULL)

```

## Aggregation

The `pat_aggregate()` function is used in the conversion of *pat* data objects
into data objects that have a uniform, typically hourly, time axis with. The 
aggregation process invovles creating regular time bins and
then calculating a variety of statistics for the data within each bin. We end
up with a dataframe with a regular time axis and multiple columns of statistics
for each input variable.

Applying our uncontroversion `pat_qc()` as the first step in the pipeline, we
can reivew which statistics are calcualted:

```{r pat_aggregate}
df <-
  example_pat_failure %>%
  pat_qc() %>%
  pat_aggregate(period = "1 hour")
class(df)
names(df)
```

### Aggregation statistics

For each variable, core statistics are calculated for the population of
measurements found in each time bin:

* mean
* median
* sd -- standard deviation
* min
* max
* count

### Student's t-Test

Every Purple Air II sensor has two separate particle detectors, each reporting
on a separate channel: A/B. When measurements in both channels agree within
measurement error then we have higher confidence in the measurements. Because
the two particle detectors are so close together we shouldn't expect any
difference in the air entering detector A or B.

The two-sample t-test is the standard statistical technique for determining
whether a difference in two means is significant or can be attributed to 
random processes. The friendliest explanation of this statistical technique
is available through a serires of 
[Khan Academy videos](https://www.khanacademy.org/math/ap-statistics/two-sample-inference#two-sample-t-test-means)

When the Purple Air sensor is functioning properly we would expect the hourly 
average of A channel PM2.5 measurements to be close to the average of B channel
PM2.5 measurements. To determine whether this NULL hypothesis holds,  the
`pat_aggregate()` function does some additional work for PM2.5 and  calculates 
the following addition two-sample t-test statistics:

* t -- t-statistic
* p -- p-value 
* df -- degrees of freedom for the t-statistic

For visual thinkers, imagine a boxplot showing the range of values from the A
and B channels for a particular hour. If the boxplots overlap, then the means,
although not identical, are not significantly different.

A picture may help. Below we display hourly boxplots for the A and B channels
during a day when they largely agree:

```{r AB_boxplot}
library(ggplot2)

# Grab a 1-day subset of the data
raw_data <- 
  example_pat_failure_B %>%
  pat_filterDate(20190611,20190611) %>%
  pat_extractData() %>%
  dplyr::select(datetime, pm25_A, pm25_B) %>%
  # Convert datetime to an hourly timestamp to use as a factor
  dplyr::mutate(datetime = strftime(datetime, "%Y%m%d%H")) %>%
  # Convert from wide to "tidy" so we can use channel as a factor
  tidyr::gather("channel", "pm25", -datetime)

# Look at a random sample of this new dataframe
dplyr::sample_n(raw_data, 10)

# Create a timeseries using boxplots
colors <- c(rgb(0.9, 0.25, 0.2), rgb(0.2, 0.25, 0.9))
ggplot(raw_data, aes(datetime, pm25, color = channel)) + 
  geom_boxplot(outlier.shape = NA,
               show.legend = FALSE) +
  scale_color_manual(values=colors) +
  geom_jitter(cex = 0.2) +
  ggtitle("A/B hourly averages")

# Compare the t-statistic for that day
agg_data <- 
  example_pat_failure_B %>%
  pat_filterDate(20190611,20190611) %>%
  pat_aggregate()

ggplot(agg_data, aes(datetime, pm25_t)) +
  geom_point() +
  ggtitle("t-statistic")
```

And here is the same for a day with serious problems:

```{r AB_boxplot_2, echo = FALSE}
library(ggplot2)

# Grab a 1-day subset of the data
raw_data <- 
  example_pat_failure_B %>%
  pat_filterDate(20190612,20190612) %>%
  pat_extractData() %>%
  dplyr::select(datetime, pm25_A, pm25_B) %>%
  # Convert datetime to an hourly timestamp to use as a factor
  dplyr::mutate(datetime = strftime(datetime, "%Y%m%d%H")) %>%
  # Convert from wide to "tidy" so we can use channel as a factor
  tidyr::gather("channel", "pm25", -datetime)

# Look at a random sample of this new dataframe
dplyr::sample_n(raw_data, 10)

# Create a timeseries using boxplots
colors <- c(rgb(0.9, 0.25, 0.2), rgb(0.2, 0.25, 0.9))
colors <- c("green","purple")
ggplot(raw_data, aes(datetime, pm25, color = channel)) + 
  geom_boxplot(outlier.shape = NA,
               show.legend = FALSE) +
  scale_color_manual(values=colors) +
  geom_jitter(cex = 0.2) +
  ggtitle("A/B hourly averages")

# Compare the t-statistic for that day
agg_data <- 
  example_pat_failure_B %>%
  pat_filterDate(20190612,20190612) %>%
  pat_aggregate()

ggplot(agg_data, aes(datetime, pm25_t)) +
  geom_point() +
  ggtitle("t-statistic")
```

We can see that values of `pm25_t > 100`, for example, only occur for hours 
where the A and B channels have hourly avergaes that are both highly precise 
(low std dev) and very different. We can thus use the `pm25_t` variable to flag
those hours where the A and B channels disagree.



