---
title: "PurpleAir Synoptic Data"
author: "Mazama Science"
date: "2020-04-10"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{PurpleAir Synoptic Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE, message=FALSE}
library(AirSensor)
library(dplyr)
library(ggplot2)

knitr::opts_chunk$set(fig.width = 7, fig.height = 5)

# NOTE: Use example PAS data for vignettes to avoid long wait-times
data("example_pas")
pas <- example_pas
```

_Synoptic data_ provides a synopsis - a comprehensive view of something at a
moment in time. This vignette demonstrates an example 
workflow for exploring air quality synoptic data using the **AirSensor**
R package and data captured by [PurpleAir](https://www.purpleair.com/) air 
quality sensors.

## Creating Current Synoptic Data (slow)

PurpleAir sensor readings are uploaded to the cloud every 120 seconds.
(Every 80 seconds prior to a May 31, 2019 firmware upgrade.)
Data are processed by PurpleAir and a version of the data is displayed on the 
PurpleAir website. 

You can generate a current PurpleAir Synoptic (PAS) object (hereafter called
a `pas`) by using the `pas_createNew()` function. A `pas` object is just a large
dataframe with `r ncol(pas)` data columns and a record for each
PurupleAir sensor channel (2 channels per sensor).

The `pas_createNew()` function perfoms the following tasks under the hood: 

1. Download a raw dataset of the entire PurpleAir network that includes both 
metadata and recent PM2.5 averages for each deployed sensor across the globe. 
See `downloadParseSynopticData()` for more info.

2. Subset and nhance the raw dataset by replacing variables with more consistent
and human readable names; adding spatial metadata for each sensor including the 
nearest official air quality monitor. For a more in depth explanation, see 
`enhanceSynopticData()`.

To create a new `pas` object you must first properly initialize the 
**MazamaSpatialUtils** package. The following example will create a brand new 
`pas` object with up-to-the-minute data:

_**NOTE: This can take up to a minute to process.**_

```{r pas_createNew, eval = FALSE}
library(AirSensor)

# Initialize spatial data processing 
library(MazamaSpatialUtils)
initializeMazamaSpatialUtils()

# Create a 'pas' object with current data
pas <- pas_createNew(countryCodes = "US")
```

## Loading Pre-generatted Synoptic Data (fast)

It is also possible to load pre-generated `pas` objects from a data archive.
These objects are updated regularly throughout each day and are typically used 
by other package functions primarily for the location metadata they contain. 
Archived `pas` objects from previous days will thus have data associated with 
near midnight of that date.

The archived `pas` objects can be loaded very quickly with the `pas_load()` 
function which obtains `pas` objects from the archive specified with
`setArchvieBaseUrl()`. When used without specifying the `datestamp` argument,
`pas_load()` will obtain the most recently processed `pas` object -- typically
less than an hour old.

```{r user_setup, eval = FALSE}
# Load packages
library(AirSensor)
library(dplyr)
library(ggplot2)

# Set location of pre-generated data files
setArchiveBaseUrl("https://airfire-data-exports.s3-us-west-2.amazonaws.com/PurpleAir/v1")

# Load the most recent archived 'pas' object
pas <- pas_load()
```

## PAS Data Structure

The `pas` dataset contains 45 columns, and each row corresponds to different 
PurpleAir sensors. For the data anlysis examples we will focus on the columns
labeled `stateCode`, `pm25_*`, `humidity`, `pressure`, `temperature`, and 
`pwfsl_closestDistance`. 

The complete list of columns is given below. Names in `ALL_CAPS` have been
retained from the PurpleAir .json file. Other columns have been renamed for
human readability.

```{r pas_names, echo = FALSE}
names(pas)
```

Let's take a quick peek at some of the PM2.5 data:

```{r}
pas %>% 
  select(starts_with("pm25_")) %>% 
  round(2) %>%
  head(5) %>% 
  knitr::kable()
``` 

### Mapping `pas` PM2.5 data

To visually explore a region, we can use our `pas` data with the `pas_leaflet()`
function to plot an interactive [leaflet](https://leafletjs.com/) map.
By default, `pas_leaflet()` will map the coordinates of each PurpleAir sensor 
and the hourly PM2.5 data. Clicking on a sensor will show sensor metadata.

```{r}
pas %>% 
  pas_leaflet()
```

If we want to narrow our selection, for example to California, and look at which 
locations have a moderate to unhealthy 6-hour average air quality rating we can 
create a script like:

```{r CAleaflet}
pas %>% 
  pas_filter(stateCode == 'CA') %>% 
  pas_filter(pm25_6hr >= 25.0) %>% 
  pas_leaflet(parameter = "pm25_6hr")
```

This code pipes our `pas` data into `dplyr::filter()` where we can set our 
selection criteria. A `stateCode` is the ISO 3166-2 state name abbreviation, 
hence we limit our filter to only accept `stateCode == 'CA'`. The `pm25_6hr` 
selection, as mentioned above, selects the 6-hour average and restricts the 
sensors to those whose PM2.5 6-hour average is above 25.0. Be sure to include 
the `"pm25_6hr"` parameter in `pas_leaflet()`.  

### Mapping `pas` auxillary data

We can also explore and utilize other PurpleAir sensor data. Check the 
`pas_leaflet()` documentation for all supported parameters.

Here is an example of humidity data captured from PurpleAir sensors across the 
state of California.
```{r}
pas %>% 
  pas_filter(stateCode == "CA") %>% 
  pas_leaflet(parameter = "humidity")
```

### Exploring PurpleAir data

Because the `pas` object is a dataframe, we can use functionality from various 
other R packages. For example, `pas` can conform to "tidyverse" syntax so we can 
use **dplyr**, **ggplot2**, and **sf** to help transform, summarize, and 
visualize `pas` data in a _tidy_ way.

Below, we demonstrate the flexibility of **AirSensor**'s `pas` data objects and 
a few examples of exploratory data analysis pipelines, focusing on the state of 
Califronia and their PurpleAir sensor data. 

```{r init_explore, message=FALSE, warning=FALSE}
# Load the extra libraries
library(sf) 
library(ggplot2)
library(fishualize) # (optional) ggplot themes

# Connect spatial database and load US county data
MazamaSpatialUtils::setSpatialDataDir('~/Data/Spatial/')
MazamaSpatialUtils::loadSpatialData("USCensusCounties")

# load California County polygon data and convert to sf 
ca_counties <- 
  subset(USCensusCounties, stateCode == "CA") %>% 
  st_as_sf()

# filter the latest pm25 and weekly pm25 of california synoptic data, convert to sf
# NOTE: be sure to set the pas sf coordinate reference system to match the counties crs 
ca_pas <- 
  pas %>% 
  pas_filter(stateCode == 'CA') %>% 
  st_as_sf(coords = c('longitude', 'latitude'), crs = st_crs(ca_counties)) 
```

#### Region Mointor Count

Using our California county feature data, we can count the number of PurpleAir 
sensors that exist in the each region feature. This is an important metric to 
determine statistical confidence we might have - i.e. the more sensors a region 
contains the more confidence we can have in our data aggregations.  

```{r n_sensors, message=FALSE, warning=FALSE}
# count the number of PurpleAir sensors in each County polygon feature
n_sensors <- 
  ca_counties %>% 
  mutate(`Number of PurpleAir Sensors` = lengths(st_contains(., ca_pas)))
```

Let's take a look at the counties that contain the most PurpleAir sensors.

```{r n_sensors_table, warning=FALSE, message=FALSE}
n_sensors %>% 
  select(`Number of PurpleAir Sensors`, name) %>% 
  st_drop_geometry() %>% 
  arrange(desc(`Number of PurpleAir Sensors`)) %>% 
  head() %>% 
  knitr::kable()
```

#### Chloropleth

Alternatively, we can visualize the amount of PurpleAir sensors per county using 
**ggplot2**, as a chloropleth map, where each county is filled with a color 
representing the number of PurpleAir sensors it contains. 

```{r n_sensors_chloropleth}
ggplot(n_sensors) + 
  geom_sf(aes(fill = `Number of PurpleAir Sensors`)) + 
  theme_void() + 
  scale_fill_fish(option = 'Cirrhilabrus_solorensis')
```

#### Barplot

Sometimes a barplot is more useful for visualizing lots of values. Here is an 
example showing the top 15 counties with the the most PurpleAir sensors that are 
active.  

```{r n_sensors_barplot, fig.height=7}
# sort the counties by the number of PurpleAir sensors and select the top 15
top15_n_sensors <- 
  n_sensors %>% 
  arrange(desc(`Number of PurpleAir Sensors`)) %>% 
  head(n = 15)

ggplot(top15_n_sensors) + 
  geom_col(aes(
    x = reorder(name, `Number of PurpleAir Sensors`), 
    y = `Number of PurpleAir Sensors`, 
    fill = `Number of PurpleAir Sensors`)) + 
  scale_fill_fish(option = 'Cirrhilabrus_solorensis') + 
  xlab('County') + 
  theme_minimal() + 
  coord_flip() 

```

#### Region Averaged Sensor Data

Our `pas` object contains not only latest ~2-minute resolution PM2.5 data 
(`pm25_current`), it also contains other, longer interval averages of PM2.5, 
e.g. `pm25_1week`, which we can use to calculate region averaged weekly PM2.5 
sensor data.  

```{r mean_pm25, warning=FALSE, message=FALSE}
# NOTE: We join the purple air data to our county data then calculate the mean per county
mean_pm25 <- 
  ca_counties %>%
  st_join(ca_pas) %>% 
  group_by(name) %>% 
  summarise(`1-week PurpleAir Average PM2.5` = mean(pm25_1week, na.rm = TRUE))
```

```{r mean_pm_table, warning=FALSE, message=FALSE}
mean_pm25 %>% 
  select(`1-week PurpleAir Average PM2.5`, name) %>% 
  st_drop_geometry() %>% 
  arrange(desc(`1-week PurpleAir Average PM2.5`)) %>% 
  head() %>% 
  knitr::kable()
```

It is important to clarify that this data **_does not_** represent a regions air 
quality distribution and instead is only a summary of the avliable PurpleAir data. 

#### Chloropleth 

In a similar fashion to that illustrated above, we can also create a 1-week 
PurpleAir averages per county chloropleth map.  

```{r mean_pm25_chloropleth, warning=FALSE, message=FALSE}
ggplot(mean_pm25) + 
  geom_sf(aes(fill = `1-week PurpleAir Average PM2.5`)) + 
  theme_void() + 
  scale_fill_fish(option = 'Trimma_lantana')
```

#### Barplot

Just as before, a barplot is sometimes a better choice. Below is an example of 
plotting the Top 15 1-week PurpleAir county averages.

```{r mean_pm25_barplot, fig.height=7, warning=FALSE, message=FALSE}
# Sort the weekly averages per county and select the top 15
top15_mean_pm25 <- 
  mean_pm25 %>% 
  arrange(desc(`1-week PurpleAir Average PM2.5`)) %>% 
  head(n = 15)

# NOTE: the color legend is not identical to the legend above
ggplot(top15_mean_pm25) + 
  geom_col(aes(
    x = reorder(name, `1-week PurpleAir Average PM2.5`), 
    y = `1-week PurpleAir Average PM2.5`, 
    fill = `1-week PurpleAir Average PM2.5`)) + 
  scale_fill_fish(option = 'Trimma_lantana') + 
  xlab('County') + 
  theme_minimal() + 
  coord_flip() 
```




----

_Mazama Science_


